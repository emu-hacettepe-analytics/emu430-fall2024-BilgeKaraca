[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Our Course Project",
    "section": "",
    "text": "I’m honored to be a member of the ANALYTICA project team.\nBelow, you’ll find a brief summary of our project. To access a detailed project description, please go to https://emu-hacettepe-analytics.github.io/emu430-fall2024-team-analytica/\nSummary\nTraffic accidents pose a significant challenge for cities, affecting safety, traffic flow, and public well-being. To better understand the dynamics of traffic accidents in İzmir, we utilized the data set titled “İzmir Metropolitan Municipality Defective, Accident Vehicle Data”, published on the İzmir Metropolitan Municipality Open Data Portal. This data set provides valuable information such as the date, type, time, and destination of traffic accidents that occurred within the metropolitan area.\nThe primary aim of this project is to analyze and interpret the data to uncover patterns, identify critical problem areas, and offer insights that can contribute to improved traffic management and accident prevention strategies.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Bilge’s Analytics Lab",
    "section": "",
    "text": "Hello! My name is Bilge Karaca.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hello, my name is Bilge Karaca. I am a senior Industrial Engineering student at Hacettepe University - Ankara. You can find further information about me below."
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nFirm xxx, position xx, year xxx\nFirm yyy, position yyy, year yyy"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nMAN Türkiye A.Ş. , Production Intern , 24/06/2024 - 22/07/2024\nGDZ Elektrik Dağıtım A.Ş. , Data Analytics Intern , 10/07/2023 - 04/09/2023"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has two parts.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the term Fall 2024 EMU430 Data Analytics course.\nPlease use left menu to navigate through my assignments.\nThe most recent update to this page was made on October 24, 2024\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#b-poll_us_election_2016-dataset",
    "href": "assignments/assignment-1.html#b-poll_us_election_2016-dataset",
    "title": "Assignment 1",
    "section": "(b) poll_us_election_2016 dataset",
    "text": "(b) poll_us_election_2016 dataset\nIn part b, I completed the tasks given on the dataset named “poll_us_election_2016”.\n\nFirst, I imported the dataset named polls_us_election_2016 in the dslabs package and wanted to see its general content.\n\n\n# importing the dataset \n\nlibrary(dslabs)\n\ndata(polls_us_election_2016)\n\n# general structre of the dataset\n\nstr(polls_us_election_2016)\n\n'data.frame':   4208 obs. of  15 variables:\n $ state           : Factor w/ 57 levels \"Alabama\",\"Alaska\",..: 50 50 50 50 50 50 50 50 37 50 ...\n $ startdate       : Date, format: \"2016-11-03\" \"2016-11-01\" ...\n $ enddate         : Date, format: \"2016-11-06\" \"2016-11-07\" ...\n $ pollster        : Factor w/ 196 levels \"ABC News/Washington Post\",..: 1 63 81 194 65 55 18 113 195 76 ...\n $ grade           : Factor w/ 10 levels \"D\",\"C-\",\"C\",\"C+\",..: 10 6 8 6 5 9 8 8 NA 8 ...\n $ samplesize      : int  2220 26574 2195 3677 16639 1295 1426 1282 8439 1107 ...\n $ population      : chr  \"lv\" \"lv\" \"lv\" \"lv\" ...\n $ rawpoll_clinton : num  47 38 42 45 47 ...\n $ rawpoll_trump   : num  43 35.7 39 41 43 ...\n $ rawpoll_johnson : num  4 5.46 6 5 3 3 5 6 6 7.1 ...\n $ rawpoll_mcmullin: num  NA NA NA NA NA NA NA NA NA NA ...\n $ adjpoll_clinton : num  45.2 43.3 42 45.7 46.8 ...\n $ adjpoll_trump   : num  41.7 41.2 38.8 40.9 42.3 ...\n $ adjpoll_johnson : num  4.63 5.18 6.84 6.07 3.73 ...\n $ adjpoll_mcmullin: num  NA NA NA NA NA NA NA NA NA NA ...\n\n\nAs seen here, the data set contains 15 variables/columns and 4208 rows. The columns contain numeric, character and factor data types.\n\nThen I displayed the first 10 lines.\n\n\n# displaying the first 10 rows \n\n(polls_us_election_2016[1:10,])\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  &lt;NA&gt;       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00               NA\n2          lv           38.03         35.69            5.46               NA\n3          lv           42.00         39.00            6.00               NA\n4          lv           45.00         41.00            5.00               NA\n5          rv           47.00         43.00            3.00               NA\n6          lv           48.00         44.00            3.00               NA\n7          lv           45.00         41.00            5.00               NA\n8          lv           44.00         40.00            6.00               NA\n9          lv           46.00         44.00            6.00               NA\n10         lv           41.20         42.70            7.10               NA\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221               NA\n2         43.34557      41.21439        5.175792               NA\n3         42.02638      38.81620        6.844734               NA\n4         45.65676      40.92004        6.069454               NA\n5         46.84089      42.33184        3.726098               NA\n6         49.02208      43.95631        3.057876               NA\n7         45.11649      40.92722        4.341786               NA\n8         43.58576      40.77325        5.365788               NA\n9         44.82594      41.59978        7.870127               NA\n10        42.92745      42.23545        6.316175               NA\n\n\n\nThen I found the total number of NA values ​​in the entire dataset.\n\n\n# calculating the total number of NA values \n\nsum(is.na(polls_us_election_2016))\n\n[1] 11604\n\n\n\nThen I assigned it as a new variable to preserve the original dataset. I continued my subsequent work on this dataset, which I named new_data.\n\n\nnew_data &lt;- polls_us_election_2016\n\n\nThen I found which columns in this data set were numeric, which were character, and which were factor. I assigned the relevant indexes of each as variables.\n\n\n# assigning indexes to variables according to data types\n\nnumeric_columns &lt;- which(sapply(new_data, is.numeric))\n\ncharacter_columns &lt;- which(sapply(new_data, is.character))\n\nfactor_columns &lt;- which(sapply(new_data, is.factor))\n\nprint(c(\"numeric: \", numeric_columns ,\"character: \", character_columns, \"Factor: \", factor_columns))\n\n                       samplesize  rawpoll_clinton    rawpoll_trump \n     \"numeric: \"              \"6\"              \"8\"              \"9\" \n rawpoll_johnson rawpoll_mcmullin  adjpoll_clinton    adjpoll_trump \n            \"10\"             \"11\"             \"12\"             \"13\" \n adjpoll_johnson adjpoll_mcmullin                        population \n            \"14\"             \"15\"    \"character: \"              \"7\" \n                            state         pollster            grade \n      \"Factor: \"              \"1\"              \"4\"              \"5\" \n\n\n\nThen, I replaced the NA values ​​in the columns with numeric data type with my birth year, 2002. I replaced the NA values ​​in the columns with data types character and factor with my name Bilge. In order to make changes to the factor type, I first had to change its type to character. After assigning the Bilge name, I changed the data type back to factor.\n\n\n# replacing NA values in numeric columns with 2002\n\nfor (i in numeric_columns) {\n  \n  new_data[is.na(new_data[, i]), i] &lt;- 2002\n  \n}\n\n# replacing NA values in character columns with Bilge\n\nfor (i in character_columns) {\n  \n  new_data[is.na(new_data[, i]), i] &lt;- \"Bilge\"\n  \n}\n\n# replacing NA values in factor columns with Bilge\n\nfor (i in factor_columns) {\n  \n  new_data[, i] &lt;- as.character(new_data[, i])  \n  new_data[is.na(new_data[, i]), i] &lt;- \"Bilge\"\n  new_data[, i] &lt;- as.factor(new_data[, i]) \n}\n\n\nThen I displayed the first 10 rows of this newly created dataset.\n\n\n# displaying first 10 row\n\nnew_data[1:10,]\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll Bilge       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00             2002\n2          lv           38.03         35.69            5.46             2002\n3          lv           42.00         39.00            6.00             2002\n4          lv           45.00         41.00            5.00             2002\n5          rv           47.00         43.00            3.00             2002\n6          lv           48.00         44.00            3.00             2002\n7          lv           45.00         41.00            5.00             2002\n8          lv           44.00         40.00            6.00             2002\n9          lv           46.00         44.00            6.00             2002\n10         lv           41.20         42.70            7.10             2002\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221             2002\n2         43.34557      41.21439        5.175792             2002\n3         42.02638      38.81620        6.844734             2002\n4         45.65676      40.92004        6.069454             2002\n5         46.84089      42.33184        3.726098             2002\n6         49.02208      43.95631        3.057876             2002\n7         45.11649      40.92722        4.341786             2002\n8         43.58576      40.77325        5.365788             2002\n9         44.82594      41.59978        7.870127             2002\n10        42.92745      42.23545        6.316175             2002\n\n\n\nFinally, I calculated how many NA values ​​were in the newly created dataset.\n\n\n# calculating the total number of NA values\n\nsum(is.na(new_data))\n\n[1] 0\n\n\nI used AI in 2 different places in this assignment.\n\nFirst, I wrote the following prompt to ChatGPT to find out which columns are numeric:\n\nIf the data type of the columns is numeric, I want to assign the indexes of those columns to a variable called numeric_columns and the answer is:\n\nnumeric_columns &lt;- which(sapply(new_data, is.numeric))\n\nI also applied this structure for character and factor ones.\n\nSecondly, I could not change the NA values ​​in the factor data type. I asked ChatGPT for help on this issue:\n\nI get an error when changing the values ​​in the factor data type. How can I solve this? According to answer, I should first convert it to the character data type and then back to the factor data type:\n\nfor (i in factor_columns) {\n  \n  new_data[, i] &lt;- as.character(new_data[, i])  \n  new_data[is.na(new_data[, i]), i] &lt;- \"Bilge\"\n  new_data[, i] &lt;- as.factor(new_data[, i]) \n}",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a-summary",
    "href": "assignments/assignment-1.html#a-summary",
    "title": "Assignment 1",
    "section": "(a) summary",
    "text": "(a) summary",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a-summary-of-the-video",
    "href": "assignments/assignment-1.html#a-summary-of-the-video",
    "title": "Assignment 1",
    "section": "(a) summary of the video",
    "text": "(a) summary of the video\nIn part A, I watched the video “Veri Bilimi ve Endüstri Mühendisliği Üzerine Sohbetler - Baykal Hafızoğlu & Erdi Daşdemir” and extracted the brief summary. I have listed the conclusions I made below:\n\nThe world of Operational Research / Analytics can be examined under 4 basic categories. These are:\n\n\nDescriptive Analytics: It covers defining data and understanding the details thoroughly. It is the easiest category in terms of complexity but low in terms of value. Data mining, time series analysis, data visualization are among the methods used.\nDiagnostic Analytics: It aims to diagnose problems. Hypothesis testing, clustering, regression are among the methods used.\nPredictive Analytics: It aims to predict what will happen in the future. Simulation, clustering, regression, machine learning are among the methods used.\nPrescriptive Analytics: It aims to make action suggestions. Although it is the category with the highest complexity, its value is also high. Optimization, heuristics, math modeling are among the methods used.\n\n\nAnalytical solutions can be divided into Operational (several times a day), Tactical (once or twice a month), Strategical (once in a few years) according to their frequency of use.\nAll projects should start with a clear and concise problem definition. At this stage, KPIs, success criteria should be determined and descriptive analyses should be performed.\nThe model produced at the model deployment stage should be suitable for the user and the sector. It should be applicable in real life and easy to use. The platform used and early prototyping are critical. Communication with the end user and the user interface are of critical importance. Even if the model is developed correctly, if it does not meet the user’s requests, the model will not work.\nAt the last stage, it should be stated how much the KPIs specified at the beginning were developed using this model. In addition, it is always better for the solution to be easily explained compared to complex models.\n\nAfterwards, I prepared two questions about this video, one open-ended and one multiple-choice:\n\nWhat is the most critical concept in the model deployment process?\nAnswer: The user interface is the most important element at this stage. The model must fully comply with the end user’s requests and needs so that the user can adapt to the model.\nWhich of the following is not one of the categories in which we classify analytical solutions based on frequency of use?\n\n\n\nTactical\nOperational\nStrategical\nExecutional\n\nAnswer: D",
    "crumbs": [
      "Assignment 1"
    ]
  }
]